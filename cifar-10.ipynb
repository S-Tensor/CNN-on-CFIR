{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport tensorflow as tf\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Dense,AveragePooling2D,BatchNormalization,Conv2D,Input,Flatten,Activation,concatenate,Dropout,GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# Hyperparameters\nbatch_size = 64\nnum_classes = 10\nnum_filter = 12\ncompression = 0.5","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load CIFAR10 Data\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\nimg_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 2s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nX_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=10/50, random_state=42)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# convert to one hot encoing \ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\ny_cv = tf.keras.utils.to_categorical(y_cv, num_classes)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)\nprint(X_cv.shape,y_cv.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(40000, 32, 32, 3) (40000, 10)\n(10000, 32, 32, 3) (10000, 10)\n(10000, 32, 32, 3) (10000, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Convolution():\n    '''\n    Before entering the first dense vlock, a convolution with 16 (or twice the \n    growth rate for BC type) output channels is performed on the input images\n    '''\n    def __init__(self, growthRate = 12, weight_decay=1E-4):\n        self.growthRate = growthRate\n        self.weight_decay = weight_decay\n        \n    def __call__(self, x):\n        \n        #x = Activation('relu')(x)\n        op = Conv2D(int(2*self.growthRate),3,padding=\"same\",use_bias=False,bias_initializer='zeros',kernel_regularizer=l2(self.weight_decay))(x)\n        \n        return op","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# test code\nin_ = Input(shape=(32,32,3))\nop = Convolution()(in_)\nprint(op.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(None, 32, 32, 24)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Bottelneck():\n    \"\"\"\n    This class implements H(l) as mentioned in paper.\n    BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3) version of H.\n    \"\"\"\n    \n    def __init__(self,growthrate = 12,weight_decay=1E-4):\n        \n        self.growthrate = growthrate\n        self.weight_decay = weight_decay\n        \n        \n    def __call__(self,x):\n        \"\"\"\n        This is where logic lives.\n        \"\"\"\n        x = BatchNormalization(beta_regularizer=l2(self.weight_decay),gamma_regularizer=l2(self.weight_decay))(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(int(4*self.growthrate),1,padding=\"same\",use_bias=False,kernel_initializer=\"he_uniform\",kernel_regularizer=l2(self.weight_decay))(x)\n        \n        x = BatchNormalization(beta_regularizer=l2(self.weight_decay),gamma_regularizer=l2(self.weight_decay))(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(int(self.growthrate),3,padding=\"same\",use_bias=False,kernel_initializer=\"he_uniform\",kernel_regularizer=l2(self.weight_decay))(x)\n        \n        return x","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Transition():\n    \"\"\"\n    This class implements transition layer as per paper.\n    BN-Con-pooling\n    \"\"\"  \n    def __init__(self,compression = 0.5,growthrate = 12,weight_decay=1E-4):\n        \n        self.compression = compression\n        self.growthrate = growthrate\n        self.weight_decay = weight_decay\n        \n    def __call__(self,x):\n        \n        nChannels = x.shape.as_list()[-1]\n        \n        x = BatchNormalization(beta_regularizer=l2(self.weight_decay),gamma_regularizer=l2(self.weight_decay))(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(int(self.compression * nChannels),1,padding=\"same\",use_bias=False,kernel_regularizer=l2(self.weight_decay))(x)\n        x = AveragePooling2D(pool_size=(2,2))(x)\n        \n        return x","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Densenet():\n    \"\"\"\n    This layer implements densenet.\n    \"\"\"\n    def __init__(self,depth,growthrate = 12,bottleneck = True):\n        \n        nDenseLayers = (depth-4) // 3\n        if bottleneck:\n            nDenseLayers //= 2\n        \n        self.nDenseLayers = nDenseLayers\n        self.growthrate = growthrate\n        \n            \n    def __call__(self,x):\n        \n        # Dense Block logic\n        \n        # convolution block\n        x = Convolution()(x)\n        \n        # 1st dense block\n        layers = []\n        for i in range(int(self.nDenseLayers)):\n            bt = Bottelneck()(x)\n            x = concatenate([x,bt])\n            \n        # transition layer\n        x = Transition()(x)\n            \n        # 2nd dense block\n        layers = []\n        for i in range(int(self.nDenseLayers)):\n            bt = Bottelneck()(x)\n            x = concatenate([x,bt])\n            \n        # transition layer\n        x = Transition()(x)\n\n        # 3rd dense block\n        layers = []\n        for i in range(int(self.nDenseLayers)):\n            bt = Bottelneck()(x)\n            x = concatenate([x,bt])\n\n        return x","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Output():\n    \"\"\"\n    This layer implements output layer.\n    \"\"\"\n    \n    def __init__(self,num_classes = 10,weight_decay=1E-4):\n        \n        self.num_classes = num_classes\n        self.weight_decay = weight_decay\n        \n    def __call__(self,x):\n      \n        x = BatchNormalization(beta_regularizer=l2(self.weight_decay),gamma_regularizer=l2(self.weight_decay))(x)\n        x = GlobalAveragePooling2D()(x)\n        #avg = AveragePooling2D(pool_size=(8,8))(x)\n        #flt = Flatten()(avg)\n        op = Dense(self.num_classes,activation=\"softmax\",kernel_regularizer=l2(self.weight_decay), bias_regularizer=l2(self.weight_decay))(x)\n        \n        return op","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_ = Input(shape=(32,32,3))\n\n# densenet\nop = Densenet(100)(in_)\n\n# output \nop = Output()(op)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = Model(inputs = in_,outputs = op)\nsgd = tf.keras.optimizers.SGD(lr = 0.1,momentum = 0.9,nesterov = True)\nmodel.compile(sgd,loss=\"categorical_crossentropy\",metrics=[\"acc\"])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":15,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_2[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 32, 32, 24)   0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 48)   192         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 32, 48)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_1[0][0]               \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n                                                                 conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 32, 32, 36)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 32, 32, 48)   192         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 32, 32, 48)   0           concatenate[0][0]                \n                                                                 conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 32, 32, 48)   192         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        activation_5[0][0]               \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 32, 32, 60)   0           concatenate_1[0][0]              \n                                                                 conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 32, 32, 60)   240         concatenate_2[0][0]              \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 60)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 48)   192         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        activation_7[0][0]               \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 32, 32, 72)   0           concatenate_2[0][0]              \n                                                                 conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 32, 32, 72)   288         concatenate_3[0][0]              \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 32, 32, 72)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_8[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 32, 32, 48)   192         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 32, 32, 48)   0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        activation_9[0][0]               \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 32, 32, 84)   0           concatenate_3[0][0]              \n                                                                 conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 32, 32, 84)   336         concatenate_4[0][0]              \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 32, 32, 84)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 32, 32, 48)   192         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 32, 32, 48)   0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        activation_11[0][0]              \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 32, 32, 96)   0           concatenate_4[0][0]              \n                                                                 conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 32, 32, 96)   384         concatenate_5[0][0]              \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 32, 32, 96)   0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_12[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 32, 32, 48)   192         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        activation_13[0][0]              \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n                                                                 conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 32, 32, 108)  432         concatenate_6[0][0]              \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 32, 32, 108)  0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_14[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        activation_15[0][0]              \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 32, 32, 120)  0           concatenate_6[0][0]              \n                                                                 conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 32, 32, 120)  480         concatenate_7[0][0]              \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 32, 32, 120)  0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 32, 32, 48)   5760        activation_16[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 32, 32, 48)   192         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 32, 32, 48)   0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 32, 32, 12)   5184        activation_17[0][0]              \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 32, 32, 132)  0           concatenate_7[0][0]              \n                                                                 conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 32, 32, 132)  528         concatenate_8[0][0]              \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 32, 32, 132)  0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 32, 32, 48)   6336        activation_18[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 32, 32, 48)   192         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 32, 32, 48)   0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 32, 32, 12)   5184        activation_19[0][0]              \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 32, 32, 144)  0           concatenate_8[0][0]              \n                                                                 conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 32, 32, 144)  576         concatenate_9[0][0]              \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 32, 32, 144)  0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 32, 32, 48)   6912        activation_20[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 32, 32, 48)   192         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 32, 32, 48)   0           batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 32, 32, 12)   5184        activation_21[0][0]              \n__________________________________________________________________________________________________\nconcatenate_10 (Concatenate)    (None, 32, 32, 156)  0           concatenate_9[0][0]              \n                                                                 conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 32, 32, 156)  624         concatenate_10[0][0]             \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 32, 32, 156)  0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 32, 32, 48)   7488        activation_22[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 32, 32, 48)   192         conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 32, 32, 12)   5184        activation_23[0][0]              \n__________________________________________________________________________________________________\nconcatenate_11 (Concatenate)    (None, 32, 32, 168)  0           concatenate_10[0][0]             \n                                                                 conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 32, 32, 168)  672         concatenate_11[0][0]             \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 32, 32, 168)  0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 32, 32, 48)   8064        activation_24[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 32, 32, 48)   192         conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 32, 32, 48)   0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 32, 32, 12)   5184        activation_25[0][0]              \n__________________________________________________________________________________________________\nconcatenate_12 (Concatenate)    (None, 32, 32, 180)  0           concatenate_11[0][0]             \n                                                                 conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 32, 32, 180)  720         concatenate_12[0][0]             \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 32, 32, 180)  0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 32, 32, 48)   8640        activation_26[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 32, 32, 48)   192         conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 32, 32, 48)   0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 32, 32, 12)   5184        activation_27[0][0]              \n__________________________________________________________________________________________________\nconcatenate_13 (Concatenate)    (None, 32, 32, 192)  0           concatenate_12[0][0]             \n                                                                 conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 32, 32, 192)  768         concatenate_13[0][0]             \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 32, 32, 192)  0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 32, 32, 48)   9216        activation_28[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 32, 32, 48)   192         conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 32, 32, 48)   0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 32, 32, 12)   5184        activation_29[0][0]              \n__________________________________________________________________________________________________\nconcatenate_14 (Concatenate)    (None, 32, 32, 204)  0           concatenate_13[0][0]             \n                                                                 conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 32, 32, 204)  816         concatenate_14[0][0]             \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 32, 32, 204)  0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 32, 32, 48)   9792        activation_30[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 32, 32, 48)   192         conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 32, 32, 48)   0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 32, 32, 12)   5184        activation_31[0][0]              \n__________________________________________________________________________________________________\nconcatenate_15 (Concatenate)    (None, 32, 32, 216)  0           concatenate_14[0][0]             \n                                                                 conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 32, 32, 216)  864         concatenate_15[0][0]             \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 32, 32, 216)  0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 32, 32, 108)  23328       activation_32[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 16, 16, 108)  0           conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 16, 16, 108)  432         average_pooling2d[0][0]          \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 16, 16, 108)  0           batch_normalization_33[0][0]     \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 16, 16, 48)   5184        activation_33[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 16, 16, 48)   192         conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 16, 16, 48)   0           batch_normalization_34[0][0]     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        activation_34[0][0]              \n__________________________________________________________________________________________________\nconcatenate_16 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d[0][0]          \n                                                                 conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 16, 16, 120)  480         concatenate_16[0][0]             \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 16, 16, 120)  0           batch_normalization_35[0][0]     \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 16, 16, 48)   5760        activation_35[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 16, 16, 48)   192         conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 16, 16, 48)   0           batch_normalization_36[0][0]     \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        activation_36[0][0]              \n__________________________________________________________________________________________________\nconcatenate_17 (Concatenate)    (None, 16, 16, 132)  0           concatenate_16[0][0]             \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 16, 16, 132)  528         concatenate_17[0][0]             \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 16, 16, 132)  0           batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 16, 16, 48)   6336        activation_37[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 16, 16, 48)   192         conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 16, 16, 48)   0           batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        activation_38[0][0]              \n__________________________________________________________________________________________________\nconcatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n                                                                 conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 16, 16, 144)  0           batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 16, 16, 48)   6912        activation_39[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 16, 16, 48)   192         conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 16, 16, 48)   0           batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        activation_40[0][0]              \n__________________________________________________________________________________________________\nconcatenate_19 (Concatenate)    (None, 16, 16, 156)  0           concatenate_18[0][0]             \n                                                                 conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_41 (BatchNo (None, 16, 16, 156)  624         concatenate_19[0][0]             \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 16, 16, 156)  0           batch_normalization_41[0][0]     \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 16, 16, 48)   7488        activation_41[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_42 (BatchNo (None, 16, 16, 48)   192         conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 16, 16, 48)   0           batch_normalization_42[0][0]     \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        activation_42[0][0]              \n__________________________________________________________________________________________________\nconcatenate_20 (Concatenate)    (None, 16, 16, 168)  0           concatenate_19[0][0]             \n                                                                 conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_43 (BatchNo (None, 16, 16, 168)  672         concatenate_20[0][0]             \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 16, 16, 168)  0           batch_normalization_43[0][0]     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 16, 16, 48)   8064        activation_43[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_44 (BatchNo (None, 16, 16, 48)   192         conv2d_45[0][0]                  \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 16, 16, 48)   0           batch_normalization_44[0][0]     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        activation_44[0][0]              \n__________________________________________________________________________________________________\nconcatenate_21 (Concatenate)    (None, 16, 16, 180)  0           concatenate_20[0][0]             \n                                                                 conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_45 (BatchNo (None, 16, 16, 180)  720         concatenate_21[0][0]             \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 16, 16, 180)  0           batch_normalization_45[0][0]     \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 16, 16, 48)   8640        activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_46 (BatchNo (None, 16, 16, 48)   192         conv2d_47[0][0]                  \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 16, 16, 48)   0           batch_normalization_46[0][0]     \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        activation_46[0][0]              \n__________________________________________________________________________________________________\nconcatenate_22 (Concatenate)    (None, 16, 16, 192)  0           concatenate_21[0][0]             \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_47 (BatchNo (None, 16, 16, 192)  768         concatenate_22[0][0]             \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 16, 16, 192)  0           batch_normalization_47[0][0]     \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 16, 16, 48)   9216        activation_47[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_48 (BatchNo (None, 16, 16, 48)   192         conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 16, 16, 48)   0           batch_normalization_48[0][0]     \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        activation_48[0][0]              \n__________________________________________________________________________________________________\nconcatenate_23 (Concatenate)    (None, 16, 16, 204)  0           concatenate_22[0][0]             \n                                                                 conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_49 (BatchNo (None, 16, 16, 204)  816         concatenate_23[0][0]             \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 16, 16, 204)  0           batch_normalization_49[0][0]     \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 16, 16, 48)   9792        activation_49[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 16, 16, 48)   192         conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 16, 16, 48)   0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 16, 16, 12)   5184        activation_50[0][0]              \n__________________________________________________________________________________________________\nconcatenate_24 (Concatenate)    (None, 16, 16, 216)  0           concatenate_23[0][0]             \n                                                                 conv2d_52[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 16, 16, 216)  864         concatenate_24[0][0]             \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 16, 16, 216)  0           batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 16, 16, 48)   10368       activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 16, 16, 48)   192         conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 16, 16, 48)   0           batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 16, 16, 12)   5184        activation_52[0][0]              \n__________________________________________________________________________________________________\nconcatenate_25 (Concatenate)    (None, 16, 16, 228)  0           concatenate_24[0][0]             \n                                                                 conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 16, 16, 228)  912         concatenate_25[0][0]             \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 16, 16, 228)  0           batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 16, 16, 48)   10944       activation_53[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 16, 16, 48)   192         conv2d_55[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 16, 16, 48)   0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 16, 16, 12)   5184        activation_54[0][0]              \n__________________________________________________________________________________________________\nconcatenate_26 (Concatenate)    (None, 16, 16, 240)  0           concatenate_25[0][0]             \n                                                                 conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_55 (BatchNo (None, 16, 16, 240)  960         concatenate_26[0][0]             \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 16, 16, 240)  0           batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 16, 16, 48)   11520       activation_55[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 16, 16, 48)   192         conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 16, 16, 48)   0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 16, 16, 12)   5184        activation_56[0][0]              \n__________________________________________________________________________________________________\nconcatenate_27 (Concatenate)    (None, 16, 16, 252)  0           concatenate_26[0][0]             \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_57 (BatchNo (None, 16, 16, 252)  1008        concatenate_27[0][0]             \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 16, 16, 252)  0           batch_normalization_57[0][0]     \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 16, 16, 48)   12096       activation_57[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_58 (BatchNo (None, 16, 16, 48)   192         conv2d_59[0][0]                  \n__________________________________________________________________________________________________\nactivation_58 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 16, 16, 12)   5184        activation_58[0][0]              \n__________________________________________________________________________________________________\nconcatenate_28 (Concatenate)    (None, 16, 16, 264)  0           concatenate_27[0][0]             \n                                                                 conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_59 (BatchNo (None, 16, 16, 264)  1056        concatenate_28[0][0]             \n__________________________________________________________________________________________________\nactivation_59 (Activation)      (None, 16, 16, 264)  0           batch_normalization_59[0][0]     \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 16, 16, 48)   12672       activation_59[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_60 (BatchNo (None, 16, 16, 48)   192         conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nactivation_60 (Activation)      (None, 16, 16, 48)   0           batch_normalization_60[0][0]     \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 16, 16, 12)   5184        activation_60[0][0]              \n__________________________________________________________________________________________________\nconcatenate_29 (Concatenate)    (None, 16, 16, 276)  0           concatenate_28[0][0]             \n                                                                 conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_61 (BatchNo (None, 16, 16, 276)  1104        concatenate_29[0][0]             \n__________________________________________________________________________________________________\nactivation_61 (Activation)      (None, 16, 16, 276)  0           batch_normalization_61[0][0]     \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 16, 16, 48)   13248       activation_61[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_62 (BatchNo (None, 16, 16, 48)   192         conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nactivation_62 (Activation)      (None, 16, 16, 48)   0           batch_normalization_62[0][0]     \n__________________________________________________________________________________________________\nconv2d_64 (Conv2D)              (None, 16, 16, 12)   5184        activation_62[0][0]              \n__________________________________________________________________________________________________\nconcatenate_30 (Concatenate)    (None, 16, 16, 288)  0           concatenate_29[0][0]             \n                                                                 conv2d_64[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_63 (BatchNo (None, 16, 16, 288)  1152        concatenate_30[0][0]             \n__________________________________________________________________________________________________\nactivation_63 (Activation)      (None, 16, 16, 288)  0           batch_normalization_63[0][0]     \n__________________________________________________________________________________________________\nconv2d_65 (Conv2D)              (None, 16, 16, 48)   13824       activation_63[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_64 (BatchNo (None, 16, 16, 48)   192         conv2d_65[0][0]                  \n__________________________________________________________________________________________________\nactivation_64 (Activation)      (None, 16, 16, 48)   0           batch_normalization_64[0][0]     \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 16, 16, 12)   5184        activation_64[0][0]              \n__________________________________________________________________________________________________\nconcatenate_31 (Concatenate)    (None, 16, 16, 300)  0           concatenate_30[0][0]             \n                                                                 conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_65 (BatchNo (None, 16, 16, 300)  1200        concatenate_31[0][0]             \n__________________________________________________________________________________________________\nactivation_65 (Activation)      (None, 16, 16, 300)  0           batch_normalization_65[0][0]     \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 16, 16, 150)  45000       activation_65[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 8, 8, 150)    0           conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_66 (BatchNo (None, 8, 8, 150)    600         average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\nactivation_66 (Activation)      (None, 8, 8, 150)    0           batch_normalization_66[0][0]     \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 8, 8, 48)     7200        activation_66[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_67 (BatchNo (None, 8, 8, 48)     192         conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nactivation_67 (Activation)      (None, 8, 8, 48)     0           batch_normalization_67[0][0]     \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        activation_67[0][0]              \n__________________________________________________________________________________________________\nconcatenate_32 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_1[0][0]        \n                                                                 conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_68 (BatchNo (None, 8, 8, 162)    648         concatenate_32[0][0]             \n__________________________________________________________________________________________________\nactivation_68 (Activation)      (None, 8, 8, 162)    0           batch_normalization_68[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 8, 8, 48)     7776        activation_68[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_69 (BatchNo (None, 8, 8, 48)     192         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nactivation_69 (Activation)      (None, 8, 8, 48)     0           batch_normalization_69[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        activation_69[0][0]              \n__________________________________________________________________________________________________\nconcatenate_33 (Concatenate)    (None, 8, 8, 174)    0           concatenate_32[0][0]             \n                                                                 conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_70 (BatchNo (None, 8, 8, 174)    696         concatenate_33[0][0]             \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 8, 8, 174)    0           batch_normalization_70[0][0]     \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 8, 8, 48)     8352        activation_70[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_71 (BatchNo (None, 8, 8, 48)     192         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 8, 8, 48)     0           batch_normalization_71[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        activation_71[0][0]              \n__________________________________________________________________________________________________\nconcatenate_34 (Concatenate)    (None, 8, 8, 186)    0           concatenate_33[0][0]             \n                                                                 conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_72 (BatchNo (None, 8, 8, 186)    744         concatenate_34[0][0]             \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 8, 8, 186)    0           batch_normalization_72[0][0]     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 8, 8, 48)     8928        activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_73 (BatchNo (None, 8, 8, 48)     192         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 8, 8, 48)     0           batch_normalization_73[0][0]     \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        activation_73[0][0]              \n__________________________________________________________________________________________________\nconcatenate_35 (Concatenate)    (None, 8, 8, 198)    0           concatenate_34[0][0]             \n                                                                 conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 8, 8, 198)    792         concatenate_35[0][0]             \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 8, 8, 198)    0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 8, 8, 48)     9504        activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 8, 8, 48)     192         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 8, 8, 48)     0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        activation_75[0][0]              \n__________________________________________________________________________________________________\nconcatenate_36 (Concatenate)    (None, 8, 8, 210)    0           concatenate_35[0][0]             \n                                                                 conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 8, 8, 210)    840         concatenate_36[0][0]             \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 8, 8, 210)    0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 8, 8, 48)     10080       activation_76[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 8, 8, 48)     192         conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 8, 8, 48)     0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        activation_77[0][0]              \n__________________________________________________________________________________________________\nconcatenate_37 (Concatenate)    (None, 8, 8, 222)    0           concatenate_36[0][0]             \n                                                                 conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 8, 8, 222)    888         concatenate_37[0][0]             \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 8, 8, 222)    0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 8, 8, 48)     10656       activation_78[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 8, 8, 48)     192         conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 8, 8, 48)     0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate_38 (Concatenate)    (None, 8, 8, 234)    0           concatenate_37[0][0]             \n                                                                 conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 8, 8, 234)    936         concatenate_38[0][0]             \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 8, 8, 234)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 8, 8, 48)     11232       activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 8, 8, 48)     192         conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 8, 8, 48)     0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        activation_81[0][0]              \n__________________________________________________________________________________________________\nconcatenate_39 (Concatenate)    (None, 8, 8, 246)    0           concatenate_38[0][0]             \n                                                                 conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 8, 8, 246)    984         concatenate_39[0][0]             \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 8, 8, 246)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 8, 8, 48)     11808       activation_82[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 8, 8, 48)     192         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 8, 8, 48)     0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        activation_83[0][0]              \n__________________________________________________________________________________________________\nconcatenate_40 (Concatenate)    (None, 8, 8, 258)    0           concatenate_39[0][0]             \n                                                                 conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 8, 8, 258)    1032        concatenate_40[0][0]             \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 8, 8, 258)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 8, 8, 48)     12384       activation_84[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 8, 8, 48)     192         conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 8, 8, 48)     0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        activation_85[0][0]              \n__________________________________________________________________________________________________\nconcatenate_41 (Concatenate)    (None, 8, 8, 270)    0           concatenate_40[0][0]             \n                                                                 conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 8, 8, 270)    1080        concatenate_41[0][0]             \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 8, 8, 270)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 8, 8, 48)     12960       activation_86[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 8, 8, 48)     192         conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 8, 8, 48)     0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 8, 8, 12)     5184        activation_87[0][0]              \n__________________________________________________________________________________________________\nconcatenate_42 (Concatenate)    (None, 8, 8, 282)    0           concatenate_41[0][0]             \n                                                                 conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 8, 8, 282)    1128        concatenate_42[0][0]             \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 8, 8, 282)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 8, 8, 48)     13536       activation_88[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 8, 8, 48)     192         conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 8, 8, 48)     0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 8, 8, 12)     5184        activation_89[0][0]              \n__________________________________________________________________________________________________\nconcatenate_43 (Concatenate)    (None, 8, 8, 294)    0           concatenate_42[0][0]             \n                                                                 conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 8, 8, 294)    1176        concatenate_43[0][0]             \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 8, 8, 294)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 8, 8, 48)     14112       activation_90[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 8, 8, 48)     192         conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 8, 8, 48)     0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 8, 8, 12)     5184        activation_91[0][0]              \n__________________________________________________________________________________________________\nconcatenate_44 (Concatenate)    (None, 8, 8, 306)    0           concatenate_43[0][0]             \n                                                                 conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 8, 8, 306)    1224        concatenate_44[0][0]             \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 8, 8, 306)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nconv2d_94 (Conv2D)              (None, 8, 8, 48)     14688       activation_92[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 8, 8, 48)     192         conv2d_94[0][0]                  \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 8, 8, 48)     0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nconv2d_95 (Conv2D)              (None, 8, 8, 12)     5184        activation_93[0][0]              \n__________________________________________________________________________________________________\nconcatenate_45 (Concatenate)    (None, 8, 8, 318)    0           concatenate_44[0][0]             \n                                                                 conv2d_95[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 8, 8, 318)    1272        concatenate_45[0][0]             \n__________________________________________________________________________________________________\nactivation_94 (Activation)      (None, 8, 8, 318)    0           batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nconv2d_96 (Conv2D)              (None, 8, 8, 48)     15264       activation_94[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 8, 8, 48)     192         conv2d_96[0][0]                  \n__________________________________________________________________________________________________\nactivation_95 (Activation)      (None, 8, 8, 48)     0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nconv2d_97 (Conv2D)              (None, 8, 8, 12)     5184        activation_95[0][0]              \n__________________________________________________________________________________________________\nconcatenate_46 (Concatenate)    (None, 8, 8, 330)    0           concatenate_45[0][0]             \n                                                                 conv2d_97[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 8, 8, 330)    1320        concatenate_46[0][0]             \n__________________________________________________________________________________________________\nactivation_96 (Activation)      (None, 8, 8, 330)    0           batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nconv2d_98 (Conv2D)              (None, 8, 8, 48)     15840       activation_96[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 8, 8, 48)     192         conv2d_98[0][0]                  \n__________________________________________________________________________________________________\nactivation_97 (Activation)      (None, 8, 8, 48)     0           batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nconv2d_99 (Conv2D)              (None, 8, 8, 12)     5184        activation_97[0][0]              \n__________________________________________________________________________________________________\nconcatenate_47 (Concatenate)    (None, 8, 8, 342)    0           concatenate_46[0][0]             \n                                                                 conv2d_99[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_98 (BatchNo (None, 8, 8, 342)    1368        concatenate_47[0][0]             \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 342)          0           batch_normalization_98[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 10)           3430        global_average_pooling2d[0][0]   \n==================================================================================================\nTotal params: 793,150\nTrainable params: 769,162\nNon-trainable params: 23,988\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#callbacks\nfrom time import time\nfrom datetime import datetime\n\n\nfrom tensorflow.python.keras.callbacks import TensorBoard\n\nfilepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\nhistory = tf.keras.callbacks.History()\n\n# tensorboard\ntensorboard = TensorBoard(log_dir=\"model_logs/{}\".format(time()))\n\nfilepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\ncheckpoint_save = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\ncallbacks_list = [checkpoint_save,learning_rate_reduction,history,tensorboard]","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    zoom_range=0.3,\n    rotation_range=15,\n    horizontal_flip=True,\n    rescale=1./255,\n    fill_mode='nearest')\n\ncv_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen.fit(X_train)\ncv_datagen.fit(X_cv)\ntest_datagen.fit(X_test)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nbatch_size = 64\nval_batch_size = 64\nsteps = len(y_train)//batch_size\nval_steps = len(y_cv)//val_batch_size","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.fit_generator(train_datagen.flow(X_train, y_train, batch_size=64),steps_per_epoch=steps,\n                    epochs=100,callbacks=callbacks_list,\n                    validation_data=cv_datagen.flow(X_cv,y_cv,batch_size=64),validation_steps = val_steps)","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n625/625 [==============================] - ETA: 0s - loss: 3.2277 - acc: 0.4225\nEpoch 00001: val_acc improved from -inf to 0.49629, saving model to weights.01-2.93.hdf5\n625/625 [==============================] - 87s 140ms/step - loss: 3.2277 - acc: 0.4225 - val_loss: 2.9305 - val_acc: 0.4963\nEpoch 2/100\n625/625 [==============================] - ETA: 0s - loss: 2.4375 - acc: 0.6049\nEpoch 00002: val_acc did not improve from 0.49629\n625/625 [==============================] - 82s 131ms/step - loss: 2.4375 - acc: 0.6049 - val_loss: 3.7146 - val_acc: 0.3785\nEpoch 3/100\n625/625 [==============================] - ETA: 0s - loss: 1.9806 - acc: 0.6879\nEpoch 00003: val_acc improved from 0.49629 to 0.58173, saving model to weights.03-2.39.hdf5\n625/625 [==============================] - 81s 130ms/step - loss: 1.9806 - acc: 0.6879 - val_loss: 2.3894 - val_acc: 0.5817\nEpoch 4/100\n625/625 [==============================] - ETA: 0s - loss: 1.6893 - acc: 0.7299\nEpoch 00004: val_acc improved from 0.58173 to 0.67488, saving model to weights.04-1.83.hdf5\n625/625 [==============================] - 82s 132ms/step - loss: 1.6893 - acc: 0.7299 - val_loss: 1.8292 - val_acc: 0.6749\nEpoch 5/100\n625/625 [==============================] - ETA: 0s - loss: 1.4907 - acc: 0.7520\nEpoch 00005: val_acc improved from 0.67488 to 0.70964, saving model to weights.05-1.57.hdf5\n625/625 [==============================] - 81s 129ms/step - loss: 1.4907 - acc: 0.7520 - val_loss: 1.5730 - val_acc: 0.7096\nEpoch 6/100\n625/625 [==============================] - ETA: 0s - loss: 1.3324 - acc: 0.7671\nEpoch 00006: val_acc did not improve from 0.70964\n625/625 [==============================] - 81s 129ms/step - loss: 1.3324 - acc: 0.7671 - val_loss: 1.6104 - val_acc: 0.6793\nEpoch 7/100\n625/625 [==============================] - ETA: 0s - loss: 1.2190 - acc: 0.7770\nEpoch 00007: val_acc improved from 0.70964 to 0.75881, saving model to weights.07-1.25.hdf5\n625/625 [==============================] - 82s 131ms/step - loss: 1.2190 - acc: 0.7770 - val_loss: 1.2451 - val_acc: 0.7588\nEpoch 8/100\n625/625 [==============================] - ETA: 0s - loss: 1.1233 - acc: 0.7874\nEpoch 00008: val_acc did not improve from 0.75881\n625/625 [==============================] - 80s 127ms/step - loss: 1.1233 - acc: 0.7874 - val_loss: 1.3794 - val_acc: 0.7142\nEpoch 9/100\n625/625 [==============================] - ETA: 0s - loss: 1.0593 - acc: 0.7958\nEpoch 00009: val_acc did not improve from 0.75881\n625/625 [==============================] - 80s 129ms/step - loss: 1.0593 - acc: 0.7958 - val_loss: 1.2801 - val_acc: 0.7263\nEpoch 10/100\n625/625 [==============================] - ETA: 0s - loss: 1.0110 - acc: 0.8009\nEpoch 00010: val_acc improved from 0.75881 to 0.80709, saving model to weights.10-0.97.hdf5\n625/625 [==============================] - 80s 129ms/step - loss: 1.0110 - acc: 0.8009 - val_loss: 0.9746 - val_acc: 0.8071\nEpoch 11/100\n625/625 [==============================] - ETA: 0s - loss: 0.9702 - acc: 0.8043\nEpoch 00011: val_acc did not improve from 0.80709\n625/625 [==============================] - 80s 127ms/step - loss: 0.9702 - acc: 0.8043 - val_loss: 1.4333 - val_acc: 0.6817\nEpoch 12/100\n625/625 [==============================] - ETA: 0s - loss: 0.9356 - acc: 0.8100\nEpoch 00012: val_acc did not improve from 0.80709\n625/625 [==============================] - 80s 127ms/step - loss: 0.9356 - acc: 0.8100 - val_loss: 1.2547 - val_acc: 0.7211\nEpoch 13/100\n625/625 [==============================] - ETA: 0s - loss: 0.9167 - acc: 0.8127\nEpoch 00013: val_acc did not improve from 0.80709\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n625/625 [==============================] - 78s 125ms/step - loss: 0.9167 - acc: 0.8127 - val_loss: 1.5450 - val_acc: 0.6799\nEpoch 14/100\n625/625 [==============================] - ETA: 0s - loss: 0.7861 - acc: 0.8506\nEpoch 00014: val_acc improved from 0.80709 to 0.84014, saving model to weights.14-0.82.hdf5\n625/625 [==============================] - 78s 125ms/step - loss: 0.7861 - acc: 0.8506 - val_loss: 0.8157 - val_acc: 0.8401\nEpoch 15/100\n625/625 [==============================] - ETA: 0s - loss: 0.7472 - acc: 0.8595\nEpoch 00015: val_acc did not improve from 0.84014\n625/625 [==============================] - 77s 124ms/step - loss: 0.7472 - acc: 0.8595 - val_loss: 0.9495 - val_acc: 0.7950\nEpoch 16/100\n625/625 [==============================] - ETA: 0s - loss: 0.7301 - acc: 0.8579\nEpoch 00016: val_acc did not improve from 0.84014\n625/625 [==============================] - 77s 123ms/step - loss: 0.7301 - acc: 0.8579 - val_loss: 0.8116 - val_acc: 0.8354\nEpoch 17/100\n625/625 [==============================] - ETA: 0s - loss: 0.7119 - acc: 0.8613\nEpoch 00017: val_acc did not improve from 0.84014\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n625/625 [==============================] - 77s 124ms/step - loss: 0.7119 - acc: 0.8613 - val_loss: 0.9048 - val_acc: 0.8084\nEpoch 18/100\n625/625 [==============================] - ETA: 0s - loss: 0.6206 - acc: 0.8901\nEpoch 00018: val_acc improved from 0.84014 to 0.87931, saving model to weights.18-0.66.hdf5\n625/625 [==============================] - 78s 125ms/step - loss: 0.6206 - acc: 0.8901 - val_loss: 0.6575 - val_acc: 0.8793\nEpoch 19/100\n625/625 [==============================] - ETA: 0s - loss: 0.6018 - acc: 0.8935\nEpoch 00019: val_acc did not improve from 0.87931\n625/625 [==============================] - 79s 126ms/step - loss: 0.6018 - acc: 0.8935 - val_loss: 0.6889 - val_acc: 0.8660\nEpoch 20/100\n625/625 [==============================] - ETA: 0s - loss: 0.5860 - acc: 0.8949\nEpoch 00020: val_acc did not improve from 0.87931\n625/625 [==============================] - 77s 123ms/step - loss: 0.5860 - acc: 0.8949 - val_loss: 0.6981 - val_acc: 0.8691\nEpoch 21/100\n625/625 [==============================] - ETA: 0s - loss: 0.5727 - acc: 0.8991\nEpoch 00021: val_acc did not improve from 0.87931\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n625/625 [==============================] - 77s 124ms/step - loss: 0.5727 - acc: 0.8991 - val_loss: 0.6947 - val_acc: 0.8641\nEpoch 22/100\n625/625 [==============================] - ETA: 0s - loss: 0.5148 - acc: 0.9165\nEpoch 00022: val_acc improved from 0.87931 to 0.89974, saving model to weights.22-0.58.hdf5\n625/625 [==============================] - 79s 126ms/step - loss: 0.5148 - acc: 0.9165 - val_loss: 0.5783 - val_acc: 0.8997\nEpoch 23/100\n625/625 [==============================] - ETA: 0s - loss: 0.4941 - acc: 0.9223\nEpoch 00023: val_acc improved from 0.89974 to 0.90154, saving model to weights.23-0.57.hdf5\n625/625 [==============================] - 78s 124ms/step - loss: 0.4941 - acc: 0.9223 - val_loss: 0.5673 - val_acc: 0.9015\nEpoch 24/100\n625/625 [==============================] - ETA: 0s - loss: 0.4830 - acc: 0.9226\nEpoch 00024: val_acc improved from 0.90154 to 0.90915, saving model to weights.24-0.54.hdf5\n625/625 [==============================] - 78s 124ms/step - loss: 0.4830 - acc: 0.9226 - val_loss: 0.5370 - val_acc: 0.9092\nEpoch 25/100\n625/625 [==============================] - ETA: 0s - loss: 0.4779 - acc: 0.9235\nEpoch 00025: val_acc did not improve from 0.90915\n625/625 [==============================] - 77s 123ms/step - loss: 0.4779 - acc: 0.9235 - val_loss: 0.6020 - val_acc: 0.8916\nEpoch 26/100\n625/625 [==============================] - ETA: 0s - loss: 0.4631 - acc: 0.9277\nEpoch 00026: val_acc did not improve from 0.90915\n625/625 [==============================] - 77s 123ms/step - loss: 0.4631 - acc: 0.9277 - val_loss: 0.5461 - val_acc: 0.9008\nEpoch 27/100\n625/625 [==============================] - ETA: 0s - loss: 0.4611 - acc: 0.9272\nEpoch 00027: val_acc did not improve from 0.90915\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n625/625 [==============================] - 77s 123ms/step - loss: 0.4611 - acc: 0.9272 - val_loss: 0.5275 - val_acc: 0.9059\nEpoch 28/100\n625/625 [==============================] - ETA: 0s - loss: 0.4201 - acc: 0.9404\nEpoch 00028: val_acc improved from 0.90915 to 0.91496, saving model to weights.28-0.50.hdf5\n625/625 [==============================] - 79s 126ms/step - loss: 0.4201 - acc: 0.9404 - val_loss: 0.4966 - val_acc: 0.9150\n","name":"stdout"},{"output_type":"stream","text":"Epoch 29/100\n625/625 [==============================] - ETA: 0s - loss: 0.4109 - acc: 0.9406\nEpoch 00029: val_acc did not improve from 0.91496\n625/625 [==============================] - 78s 125ms/step - loss: 0.4109 - acc: 0.9406 - val_loss: 0.5191 - val_acc: 0.9104\nEpoch 30/100\n625/625 [==============================] - ETA: 0s - loss: 0.4047 - acc: 0.9431\nEpoch 00030: val_acc improved from 0.91496 to 0.91727, saving model to weights.30-0.49.hdf5\n625/625 [==============================] - 79s 126ms/step - loss: 0.4047 - acc: 0.9431 - val_loss: 0.4924 - val_acc: 0.9173\nEpoch 31/100\n625/625 [==============================] - ETA: 0s - loss: 0.3943 - acc: 0.9463\nEpoch 00031: val_acc did not improve from 0.91727\n625/625 [==============================] - 79s 127ms/step - loss: 0.3943 - acc: 0.9463 - val_loss: 0.5243 - val_acc: 0.9077\nEpoch 32/100\n625/625 [==============================] - ETA: 0s - loss: 0.3885 - acc: 0.9476\nEpoch 00032: val_acc did not improve from 0.91727\n625/625 [==============================] - 77s 124ms/step - loss: 0.3885 - acc: 0.9476 - val_loss: 0.4928 - val_acc: 0.9142\nEpoch 33/100\n625/625 [==============================] - ETA: 0s - loss: 0.3826 - acc: 0.9503\nEpoch 00033: val_acc improved from 0.91727 to 0.92077, saving model to weights.33-0.49.hdf5\n625/625 [==============================] - 78s 125ms/step - loss: 0.3826 - acc: 0.9503 - val_loss: 0.4880 - val_acc: 0.9208\nEpoch 34/100\n625/625 [==============================] - ETA: 0s - loss: 0.3811 - acc: 0.9485\nEpoch 00034: val_acc did not improve from 0.92077\n625/625 [==============================] - 77s 123ms/step - loss: 0.3811 - acc: 0.9485 - val_loss: 0.5083 - val_acc: 0.9147\nEpoch 35/100\n625/625 [==============================] - ETA: 0s - loss: 0.3761 - acc: 0.9494\nEpoch 00035: val_acc did not improve from 0.92077\n625/625 [==============================] - 80s 128ms/step - loss: 0.3761 - acc: 0.9494 - val_loss: 0.4918 - val_acc: 0.9134\nEpoch 36/100\n625/625 [==============================] - ETA: 0s - loss: 0.3702 - acc: 0.9510\nEpoch 00036: val_acc did not improve from 0.92077\n\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n625/625 [==============================] - 78s 124ms/step - loss: 0.3702 - acc: 0.9510 - val_loss: 0.4930 - val_acc: 0.9191\nEpoch 37/100\n625/625 [==============================] - ETA: 0s - loss: 0.3491 - acc: 0.9577\nEpoch 00037: val_acc improved from 0.92077 to 0.92508, saving model to weights.37-0.47.hdf5\n625/625 [==============================] - 79s 126ms/step - loss: 0.3491 - acc: 0.9577 - val_loss: 0.4738 - val_acc: 0.9251\nEpoch 38/100\n625/625 [==============================] - ETA: 0s - loss: 0.3408 - acc: 0.9602\nEpoch 00038: val_acc did not improve from 0.92508\n625/625 [==============================] - 78s 125ms/step - loss: 0.3408 - acc: 0.9602 - val_loss: 0.4695 - val_acc: 0.9211\nEpoch 39/100\n625/625 [==============================] - ETA: 0s - loss: 0.3358 - acc: 0.9618\nEpoch 00039: val_acc did not improve from 0.92508\n625/625 [==============================] - 77s 123ms/step - loss: 0.3358 - acc: 0.9618 - val_loss: 0.4710 - val_acc: 0.9216\nEpoch 40/100\n625/625 [==============================] - ETA: 0s - loss: 0.3377 - acc: 0.9609\nEpoch 00040: val_acc did not improve from 0.92508\n\nEpoch 00040: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n625/625 [==============================] - 77s 123ms/step - loss: 0.3377 - acc: 0.9609 - val_loss: 0.4701 - val_acc: 0.9226\nEpoch 41/100\n625/625 [==============================] - ETA: 0s - loss: 0.3232 - acc: 0.9656\nEpoch 00041: val_acc improved from 0.92508 to 0.92899, saving model to weights.41-0.45.hdf5\n625/625 [==============================] - 78s 125ms/step - loss: 0.3232 - acc: 0.9656 - val_loss: 0.4520 - val_acc: 0.9290\nEpoch 42/100\n625/625 [==============================] - ETA: 0s - loss: 0.3169 - acc: 0.9686\nEpoch 00042: val_acc did not improve from 0.92899\n625/625 [==============================] - 78s 126ms/step - loss: 0.3169 - acc: 0.9686 - val_loss: 0.4577 - val_acc: 0.9253\nEpoch 43/100\n625/625 [==============================] - ETA: 0s - loss: 0.3140 - acc: 0.9694\nEpoch 00043: val_acc did not improve from 0.92899\n625/625 [==============================] - 77s 123ms/step - loss: 0.3140 - acc: 0.9694 - val_loss: 0.4566 - val_acc: 0.9270\nEpoch 44/100\n625/625 [==============================] - ETA: 0s - loss: 0.3105 - acc: 0.9707\nEpoch 00044: val_acc did not improve from 0.92899\n\nEpoch 00044: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n625/625 [==============================] - 78s 125ms/step - loss: 0.3105 - acc: 0.9707 - val_loss: 0.4496 - val_acc: 0.9280\nEpoch 45/100\n625/625 [==============================] - ETA: 0s - loss: 0.3046 - acc: 0.9709\nEpoch 00045: val_acc did not improve from 0.92899\n625/625 [==============================] - 78s 125ms/step - loss: 0.3046 - acc: 0.9709 - val_loss: 0.4476 - val_acc: 0.9283\nEpoch 46/100\n625/625 [==============================] - ETA: 0s - loss: 0.3066 - acc: 0.9705\nEpoch 00046: val_acc did not improve from 0.92899\n625/625 [==============================] - 77s 124ms/step - loss: 0.3066 - acc: 0.9705 - val_loss: 0.4474 - val_acc: 0.9279\nEpoch 47/100\n625/625 [==============================] - ETA: 0s - loss: 0.3025 - acc: 0.9717\nEpoch 00047: val_acc did not improve from 0.92899\n\nEpoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n625/625 [==============================] - 78s 124ms/step - loss: 0.3025 - acc: 0.9717 - val_loss: 0.4510 - val_acc: 0.9280\nEpoch 48/100\n625/625 [==============================] - ETA: 0s - loss: 0.3033 - acc: 0.9718\nEpoch 00048: val_acc did not improve from 0.92899\n625/625 [==============================] - 77s 124ms/step - loss: 0.3033 - acc: 0.9718 - val_loss: 0.4491 - val_acc: 0.9280\nEpoch 49/100\n625/625 [==============================] - ETA: 0s - loss: 0.2997 - acc: 0.9732\nEpoch 00049: val_acc did not improve from 0.92899\n625/625 [==============================] - 78s 125ms/step - loss: 0.2997 - acc: 0.9732 - val_loss: 0.4485 - val_acc: 0.9280\nEpoch 50/100\n625/625 [==============================] - ETA: 0s - loss: 0.2973 - acc: 0.9735\nEpoch 00050: val_acc did not improve from 0.92899\n\nEpoch 00050: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.\n625/625 [==============================] - 77s 123ms/step - loss: 0.2973 - acc: 0.9735 - val_loss: 0.4511 - val_acc: 0.9275\nEpoch 51/100\n625/625 [==============================] - ETA: 0s - loss: 0.2975 - acc: 0.9732\nEpoch 00051: val_acc did not improve from 0.92899\n625/625 [==============================] - 77s 123ms/step - loss: 0.2975 - acc: 0.9732 - val_loss: 0.4502 - val_acc: 0.9275\nEpoch 52/100\n625/625 [==============================] - ETA: 0s - loss: 0.2964 - acc: 0.9745\nEpoch 00052: val_acc did not improve from 0.92899\n625/625 [==============================] - 78s 125ms/step - loss: 0.2964 - acc: 0.9745 - val_loss: 0.4482 - val_acc: 0.9290\nEpoch 53/100\n625/625 [==============================] - ETA: 0s - loss: 0.2968 - acc: 0.9733\nEpoch 00053: val_acc improved from 0.92899 to 0.92909, saving model to weights.53-0.45.hdf5\n625/625 [==============================] - 79s 126ms/step - loss: 0.2968 - acc: 0.9733 - val_loss: 0.4473 - val_acc: 0.9291\nEpoch 54/100\n625/625 [==============================] - ETA: 0s - loss: 0.2970 - acc: 0.9739\nEpoch 00054: val_acc improved from 0.92909 to 0.92989, saving model to weights.54-0.45.hdf5\n625/625 [==============================] - 78s 125ms/step - loss: 0.2970 - acc: 0.9739 - val_loss: 0.4469 - val_acc: 0.9299\nEpoch 55/100\n625/625 [==============================] - ETA: 0s - loss: 0.2947 - acc: 0.9741\nEpoch 00055: val_acc did not improve from 0.92989\n625/625 [==============================] - 78s 125ms/step - loss: 0.2947 - acc: 0.9741 - val_loss: 0.4481 - val_acc: 0.9286\nEpoch 56/100\n625/625 [==============================] - ETA: 0s - loss: 0.2942 - acc: 0.9754\nEpoch 00056: val_acc improved from 0.92989 to 0.93009, saving model to weights.56-0.45.hdf5\n625/625 [==============================] - 79s 126ms/step - loss: 0.2942 - acc: 0.9754 - val_loss: 0.4457 - val_acc: 0.9301\nEpoch 57/100\n","name":"stdout"},{"output_type":"stream","text":"625/625 [==============================] - ETA: 0s - loss: 0.2947 - acc: 0.9750\nEpoch 00057: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2947 - acc: 0.9750 - val_loss: 0.4477 - val_acc: 0.9299\nEpoch 58/100\n625/625 [==============================] - ETA: 0s - loss: 0.2943 - acc: 0.9751\nEpoch 00058: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2943 - acc: 0.9751 - val_loss: 0.4469 - val_acc: 0.9299\nEpoch 59/100\n625/625 [==============================] - ETA: 0s - loss: 0.2919 - acc: 0.9752\nEpoch 00059: val_acc did not improve from 0.93009\n\nEpoch 00059: ReduceLROnPlateau reducing learning rate to 0.0001.\n625/625 [==============================] - 77s 124ms/step - loss: 0.2919 - acc: 0.9752 - val_loss: 0.4486 - val_acc: 0.9296\nEpoch 60/100\n625/625 [==============================] - ETA: 0s - loss: 0.2931 - acc: 0.9743\nEpoch 00060: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2931 - acc: 0.9743 - val_loss: 0.4480 - val_acc: 0.9289\nEpoch 61/100\n625/625 [==============================] - ETA: 0s - loss: 0.2922 - acc: 0.9755\nEpoch 00061: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2922 - acc: 0.9755 - val_loss: 0.4479 - val_acc: 0.9285\nEpoch 62/100\n625/625 [==============================] - ETA: 0s - loss: 0.2922 - acc: 0.9751\nEpoch 00062: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2922 - acc: 0.9751 - val_loss: 0.4501 - val_acc: 0.9276\nEpoch 63/100\n625/625 [==============================] - ETA: 0s - loss: 0.2933 - acc: 0.9750\nEpoch 00063: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2933 - acc: 0.9750 - val_loss: 0.4490 - val_acc: 0.9287\nEpoch 64/100\n625/625 [==============================] - ETA: 0s - loss: 0.2918 - acc: 0.9755\nEpoch 00064: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 125ms/step - loss: 0.2918 - acc: 0.9755 - val_loss: 0.4483 - val_acc: 0.9293\nEpoch 65/100\n625/625 [==============================] - ETA: 0s - loss: 0.2936 - acc: 0.9747\nEpoch 00065: val_acc did not improve from 0.93009\n625/625 [==============================] - 79s 127ms/step - loss: 0.2936 - acc: 0.9747 - val_loss: 0.4475 - val_acc: 0.9293\nEpoch 66/100\n625/625 [==============================] - ETA: 0s - loss: 0.2900 - acc: 0.9758\nEpoch 00066: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2900 - acc: 0.9758 - val_loss: 0.4480 - val_acc: 0.9292\nEpoch 67/100\n625/625 [==============================] - ETA: 0s - loss: 0.2902 - acc: 0.9761\nEpoch 00067: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2902 - acc: 0.9761 - val_loss: 0.4490 - val_acc: 0.9287\nEpoch 68/100\n625/625 [==============================] - ETA: 0s - loss: 0.2928 - acc: 0.9752\nEpoch 00068: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2928 - acc: 0.9752 - val_loss: 0.4492 - val_acc: 0.9286\nEpoch 69/100\n625/625 [==============================] - ETA: 0s - loss: 0.2914 - acc: 0.9756\nEpoch 00069: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2914 - acc: 0.9756 - val_loss: 0.4493 - val_acc: 0.9282\nEpoch 70/100\n625/625 [==============================] - ETA: 0s - loss: 0.2923 - acc: 0.9751\nEpoch 00070: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2923 - acc: 0.9751 - val_loss: 0.4482 - val_acc: 0.9288\nEpoch 71/100\n625/625 [==============================] - ETA: 0s - loss: 0.2885 - acc: 0.9764\nEpoch 00071: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2885 - acc: 0.9764 - val_loss: 0.4479 - val_acc: 0.9292\nEpoch 72/100\n625/625 [==============================] - ETA: 0s - loss: 0.2897 - acc: 0.9764\nEpoch 00072: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2897 - acc: 0.9764 - val_loss: 0.4475 - val_acc: 0.9292\nEpoch 73/100\n625/625 [==============================] - ETA: 0s - loss: 0.2902 - acc: 0.9753\nEpoch 00073: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2902 - acc: 0.9753 - val_loss: 0.4494 - val_acc: 0.9284\nEpoch 74/100\n625/625 [==============================] - ETA: 0s - loss: 0.2915 - acc: 0.9760\nEpoch 00074: val_acc did not improve from 0.93009\n625/625 [==============================] - 76s 122ms/step - loss: 0.2915 - acc: 0.9760 - val_loss: 0.4482 - val_acc: 0.9290\nEpoch 75/100\n625/625 [==============================] - ETA: 0s - loss: 0.2875 - acc: 0.9770\nEpoch 00075: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2875 - acc: 0.9770 - val_loss: 0.4491 - val_acc: 0.9285\nEpoch 76/100\n625/625 [==============================] - ETA: 0s - loss: 0.2886 - acc: 0.9772\nEpoch 00076: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2886 - acc: 0.9772 - val_loss: 0.4469 - val_acc: 0.9285\nEpoch 77/100\n625/625 [==============================] - ETA: 0s - loss: 0.2895 - acc: 0.9762\nEpoch 00077: val_acc did not improve from 0.93009\n625/625 [==============================] - 76s 122ms/step - loss: 0.2895 - acc: 0.9762 - val_loss: 0.4458 - val_acc: 0.9294\nEpoch 78/100\n625/625 [==============================] - ETA: 0s - loss: 0.2905 - acc: 0.9758\nEpoch 00078: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2905 - acc: 0.9758 - val_loss: 0.4475 - val_acc: 0.9292\nEpoch 79/100\n625/625 [==============================] - ETA: 0s - loss: 0.2876 - acc: 0.9770\nEpoch 00079: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2876 - acc: 0.9770 - val_loss: 0.4477 - val_acc: 0.9288\nEpoch 80/100\n625/625 [==============================] - ETA: 0s - loss: 0.2903 - acc: 0.9758\nEpoch 00080: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2903 - acc: 0.9758 - val_loss: 0.4477 - val_acc: 0.9288\nEpoch 81/100\n625/625 [==============================] - ETA: 0s - loss: 0.2903 - acc: 0.9761\nEpoch 00081: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2903 - acc: 0.9761 - val_loss: 0.4477 - val_acc: 0.9286\nEpoch 82/100\n625/625 [==============================] - ETA: 0s - loss: 0.2896 - acc: 0.9761\nEpoch 00082: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2896 - acc: 0.9761 - val_loss: 0.4473 - val_acc: 0.9286\nEpoch 83/100\n625/625 [==============================] - ETA: 0s - loss: 0.2892 - acc: 0.9773\nEpoch 00083: val_acc did not improve from 0.93009\n625/625 [==============================] - 79s 127ms/step - loss: 0.2892 - acc: 0.9773 - val_loss: 0.4497 - val_acc: 0.9287\nEpoch 84/100\n625/625 [==============================] - ETA: 0s - loss: 0.2896 - acc: 0.9761\nEpoch 00084: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2896 - acc: 0.9761 - val_loss: 0.4486 - val_acc: 0.9289\nEpoch 85/100\n625/625 [==============================] - ETA: 0s - loss: 0.2868 - acc: 0.9772\nEpoch 00085: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2868 - acc: 0.9772 - val_loss: 0.4472 - val_acc: 0.9292\nEpoch 86/100\n625/625 [==============================] - ETA: 0s - loss: 0.2889 - acc: 0.9761\nEpoch 00086: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 125ms/step - loss: 0.2889 - acc: 0.9761 - val_loss: 0.4476 - val_acc: 0.9287\nEpoch 87/100\n625/625 [==============================] - ETA: 0s - loss: 0.2867 - acc: 0.9769\nEpoch 00087: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2867 - acc: 0.9769 - val_loss: 0.4475 - val_acc: 0.9289\n","name":"stdout"},{"output_type":"stream","text":"Epoch 88/100\n625/625 [==============================] - ETA: 0s - loss: 0.2879 - acc: 0.9764\nEpoch 00088: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2879 - acc: 0.9764 - val_loss: 0.4483 - val_acc: 0.9289\nEpoch 89/100\n625/625 [==============================] - ETA: 0s - loss: 0.2865 - acc: 0.9766\nEpoch 00089: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2865 - acc: 0.9766 - val_loss: 0.4485 - val_acc: 0.9287\nEpoch 90/100\n625/625 [==============================] - ETA: 0s - loss: 0.2881 - acc: 0.9764\nEpoch 00090: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 125ms/step - loss: 0.2881 - acc: 0.9764 - val_loss: 0.4481 - val_acc: 0.9283\nEpoch 91/100\n625/625 [==============================] - ETA: 0s - loss: 0.2866 - acc: 0.9778\nEpoch 00091: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2866 - acc: 0.9778 - val_loss: 0.4469 - val_acc: 0.9287\nEpoch 92/100\n625/625 [==============================] - ETA: 0s - loss: 0.2864 - acc: 0.9763\nEpoch 00092: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2864 - acc: 0.9763 - val_loss: 0.4482 - val_acc: 0.9284\nEpoch 93/100\n625/625 [==============================] - ETA: 0s - loss: 0.2866 - acc: 0.9772\nEpoch 00093: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 125ms/step - loss: 0.2866 - acc: 0.9772 - val_loss: 0.4470 - val_acc: 0.9296\nEpoch 94/100\n625/625 [==============================] - ETA: 0s - loss: 0.2861 - acc: 0.9772\nEpoch 00094: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2861 - acc: 0.9772 - val_loss: 0.4483 - val_acc: 0.9292\nEpoch 95/100\n625/625 [==============================] - ETA: 0s - loss: 0.2860 - acc: 0.9774\nEpoch 00095: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2860 - acc: 0.9774 - val_loss: 0.4465 - val_acc: 0.9297\nEpoch 96/100\n625/625 [==============================] - ETA: 0s - loss: 0.2869 - acc: 0.9763\nEpoch 00096: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 123ms/step - loss: 0.2869 - acc: 0.9763 - val_loss: 0.4467 - val_acc: 0.9287\nEpoch 97/100\n625/625 [==============================] - ETA: 0s - loss: 0.2832 - acc: 0.9784\nEpoch 00097: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2832 - acc: 0.9784 - val_loss: 0.4476 - val_acc: 0.9295\nEpoch 98/100\n625/625 [==============================] - ETA: 0s - loss: 0.2851 - acc: 0.9773\nEpoch 00098: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2851 - acc: 0.9773 - val_loss: 0.4485 - val_acc: 0.9282\nEpoch 99/100\n625/625 [==============================] - ETA: 0s - loss: 0.2896 - acc: 0.9757\nEpoch 00099: val_acc did not improve from 0.93009\n625/625 [==============================] - 77s 124ms/step - loss: 0.2896 - acc: 0.9757 - val_loss: 0.4484 - val_acc: 0.9291\nEpoch 100/100\n625/625 [==============================] - ETA: 0s - loss: 0.2835 - acc: 0.9778\nEpoch 00100: val_acc did not improve from 0.93009\n625/625 [==============================] - 78s 124ms/step - loss: 0.2835 - acc: 0.9778 - val_loss: 0.4467 - val_acc: 0.9292\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f5968553150>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"LOG_DIR = './model_logs'\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\n\nget_ipython().system_raw('./ngrok http 6006 &')","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate_generator(test_datagen.flow(X_test, y_test, batch_size=64), verbose=1)","execution_count":24,"outputs":[{"output_type":"stream","text":"157/157 [==============================] - 5s 33ms/step - loss: 0.4638 - acc: 0.9247\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":25,"outputs":[{"output_type":"stream","text":"Test loss: 0.4638172388076782\nTest accuracy: 0.9247000217437744\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport seaborn as sns\n%matplotlib inline\n# Look at confusion matrix \n#Note, this code is taken straight from the SKLEARN website, an nice way of viewing confusion matrix.\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n# Predict the values from the validation dataset\nX_test = X_test.astype('float32')\nX_test /= 255","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred, axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test, axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10))","execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}